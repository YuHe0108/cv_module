[net]
# Testing
# batch=1
# subdivisions=1
# Training
batch = 32
subdivisions = 1
width = 32
height = 32
channels = 3
momentum = 0.9
decay = 0.0005
angle = 0
saturation = 1.5
exposure = 1.5
hue = .1

learning_rate = 0.001
burn_in = 1000
max_batches = 500200
policy = steps
steps = 400000,450000
scales = .1,.1

[convolutional]
batch_normalize = 1
filters = 64
size = 3
stride = 1
pad = 1
activation = relu

[maxpool]
size = 2
stride = 2

[convolutional]
batch_normalize = 1
filters = 64
size = 3
stride = 1
pad = 1
activation = relu

[convolutional]
batch_normalize = 1
filters = 64
size = 3
stride = 1
pad = 1
activation = relu

[shortcut]
from = -3
activation = linear

[maxpool]
size = 2
stride = 2

[convolutional]
batch_normalize = 1
filters = 128
size = 3
stride = 1
pad = 1
activation = relu

[convolutional]
batch_normalize = 1
filters = 128
size = 3
stride = 1
pad = 1
activation = relu

[convolutional]
batch_normalize = 1
filters = 128
size = 3
stride = 1
pad = 1
activation = relu

[shortcut]
from = -3
activation = linear

[convolutional]
batch_normalize = 1
filters = 64
size = 3
stride = 1
pad = 1
activation = relu

[maxpool]
size = 2
stride = 2

[flatten]
flatten = 1
units = 1024

[linear]
units = 128
dropout = 0.2
activation = relu

[linear]
units = 10
dropout = 0
activation = linear_ac